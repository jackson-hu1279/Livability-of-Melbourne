{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import couchdb3\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "\n",
    "def reform_tweet(raw_tweet):\n",
    "    \"\"\"\n",
    "    Reform the tweet data into a dictionary form.\n",
    "    Each tweet is a dictionary contains: tweet_id, text, author_id, create_at, geo\n",
    "    \"\"\"\n",
    "    tweet_dict = dict()\n",
    "    tweet_dict['_id'] = str(raw_tweet.id)\n",
    "    tweet_dict['author_id'] = raw_tweet.author_id\n",
    "    tweet_dict['text'] = raw_tweet.text\n",
    "    tweet_dict['created_at'] = str(raw_tweet.created_at)\n",
    "    tweet_dict['geo'] = str(raw_tweet.geo)\n",
    "\n",
    "    return tweet_dict\n",
    "\n",
    "\n",
    "def preprocess(raw_tweet, id_set, tweet_list):\n",
    "    \"\"\"\n",
    "    Process all tweets in one turn, remove tweets withou geo info\n",
    "    \"\"\"\n",
    "    for data in raw_tweet:\n",
    "      if(data.id not in id_set):  #remove duplicate\n",
    "        id_set.add(data.id)\n",
    "        tweet_list.append(reform_tweet(data))\n",
    "    \n",
    "    return tweet_list, id_set\n",
    "\n",
    "\n",
    "def get_tweet_1(query, token, tweets_each_turn, next_page = None):\n",
    "    \"\"\"\n",
    "    Get tweet using Twitter API 2.0. \n",
    "    Using keywords(query) as a main parameter\n",
    "    Caputure tweet_id, text, geo, author_id, create_at\n",
    "    \"\"\"\n",
    "    client = tweepy.Client(bearer_token= token)\n",
    "    # each time capture 100 tweets\n",
    "    tweets = client.search_recent_tweets(query=query, tweet_fields=['author_id', 'created_at', 'geo'], max_results=tweets_each_turn, next_token=next_page)\n",
    "\n",
    "    print(tweets.meta)\n",
    "\n",
    "    return tweets.data, tweets.meta['next_token']\n",
    "\n",
    "\n",
    "def crawler(query, tokens, tweets_each_turn, turns, file_name):\n",
    "    \"\"\"\n",
    "    Main function. Use query as filter, token for authocation, and number of tweets each turn\n",
    "    Turns suggest how many turns this function will run\n",
    "    Get tweets from Twitter\n",
    "    Remove tweets without geo\n",
    "    Refrom tweets to dictionary type\n",
    "    Save tweets as pickle file\n",
    "    Automatically repeat this process.\n",
    "    For one token, speed limit is 900 tweets/15min(1/sec)\n",
    "    \"\"\"\n",
    "\n",
    "    time_gap = int (tweets_each_turn / len(tokens)) + 1\n",
    "    count = 0\n",
    "    next_page = None\n",
    "    tweet_list = []\n",
    "    id_set = set()\n",
    "    while(count < turns):\n",
    "        for token in tokens:\n",
    "            data, next_page = get_tweet_1(query, token, tweets_each_turn, next_page)\n",
    "            tweet_list, id_set = preprocess(data, id_set, tweet_list)\n",
    "            time.sleep(time_gap)\n",
    "        \n",
    "        count = count + 1\n",
    "\n",
    "    output = open(file_name,'wb')\n",
    "    pickle.dump(tweet_list, output)\n",
    "    output.close()\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_couchDB(client, tweet_data, db_name):\n",
    "    if(client.up() == True):\n",
    "        print(\"Connected to CouchDB\")\n",
    "    else:\n",
    "        print(\"Unable to connect to CouchDB\")\n",
    "        return\n",
    "\n",
    "    if( db_name not in client.all_dbs()):\n",
    "        client.create(db_name)\n",
    "    \n",
    "    db = client.get(db_name)\n",
    "\n",
    "    for data in tweet_data:\n",
    "        db.save(data)\n",
    "    \n",
    "    print(\"Data is successfully saved to CouchDB\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEARER_TOKEN = [\"AAAAAAAAAAAAAAAAAAAAALWBbQEAAAAA%2FbQ0tpIE3uy14yUmYU0AiocoH6c%3DDkX3Fl2TdMFgRBCivYCSMajfqglkm8DkyylcAXkUFFceAIOBRB\",\n",
    "\"AAAAAAAAAAAAAAAAAAAAAF1YbQEAAAAAEOLr26RmQ1V0eVq1xDR%2FUioYOKY%3DAHtIcXsDHv5lnyzj8KAdzlEbVVaC85k3uvvUvYESyeK0h9knqM\"]                \n",
    "query1 = '#Melbourne lang:en'\n",
    "query2 = 'Melbourne rape lang:en'\n",
    "query3 = 'Melbourne family violence lang:en'\n",
    "\n",
    "client = couchdb3.Server(\n",
    "    \"http://172.26.132.196:5984\",\n",
    "    user=\"admin\",\n",
    "    password=\"admin\"\n",
    ")\n",
    "db_name = \"renkai_tweets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.up()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = client.get(db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = db.get('1519924999435747328')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '1519924999435747328',\n",
       " '_rev': '1-b2770f726bbf58c857e0a2268b8c26a2',\n",
       " 'author_id': 2928313861,\n",
       " 'text': 'RT @SEComForum: Hey @ibacVic in terms of transparency, are you going to publish the full interview of @DanielAndrewsMP for the public to seâ€¦',\n",
       " 'created_at': '2022-04-29 06:22:13+00:00'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'None'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'newest_id': '1519931529782525952', 'oldest_id': '1519928804961042434', 'result_count': 10, 'next_token': 'b26v89c19zqg8o3fpytotfyenn54e4yzbd3usbc592l4t'}\n",
      "{'newest_id': '1519928624287264768', 'oldest_id': '1519926313905176576', 'result_count': 10, 'next_token': 'b26v89c19zqg8o3fpytotfyekktx5xnmrzwl786acp4e5'}\n"
     ]
    }
   ],
   "source": [
    "crawler(query1, BEARER_TOKEN, 10, 1, \"test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = open('test.pkl','rb')\n",
    "data1 = pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': '1519931529782525952',\n",
       " 'author_id': 351431656,\n",
       " 'text': 'MULTILINGUAL NEWS SERVICE GREEK 29 April 22.\\nAudio resources in your language to keep your community informed and safe during COVID-19.\\n#news #covid19 #community #melbourne #Australia #multilingual #multicultural #radio #greek #vaccine\\n https://t.co/azMCiR1vjH',\n",
       " 'created_at': '2022-04-29 06:48:10+00:00',\n",
       " 'geo': 'None'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to CouchDB\n",
      "Data is successfully saved to CouchDB\n"
     ]
    }
   ],
   "source": [
    "save_to_couchDB(client, data1, db_name)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2ce5bc9348202541e82489c0c7283087ccf1347e0b0a31df1bd21360ebe99e17"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
